# numpy를 사용하여 여러가지 벡터 연산을 연습하고, 실제 데이터 유사도를 계산해봅시다.

import pandas as pd
import numpy as np

data = pd.DataFrame(data=np.random.randn(6,6), columns=["A", "B", "C", "D", "E", "F"])
data

data[(data > 2).any(axis=1)]

# kaggle data

survey = pd.read_csv('./kaggle_survey_2021_responses.csv')
survey

survey['Q4']

# Q. 현재 데이터줄에 학사학위를 취득할 사람들을 뽑아보세요.
survey[survey['Q4'] == 'Bachelor’s degree']
# survey.loc[survey.Q4 == 'Bachelor’s degree',:]

# set(survey.Q3)
survey.Q3.unique()

# Korea라는 문자열이 포함된 모든 row에 대해 T/F
survey[survey.Q3.str.contains("Korea")]

# Q. 한국 사람들을 찾아주세요
survey[survey['Q3'] == 'South Korea']
# survey.loc[survey.Q3 == 'South Korea', :]

# Q. 한국 유저들이 데이터분석에서 많이 사용하는 Programming Language 중에 Top 5를 찾아보세요.
survey[survey['Q3'] == 'South Korea']['Q7_Part_1']
survey[survey['Q3'] == 'South Korea']['Q7_Part_2']
survey[survey['Q3'] == 'South Korea']['Q7_Part_3']
survey[survey['Q3'] == 'South Korea']['Q7_Part_4']
survey[survey['Q3'] == 'South Korea']['Q7_Part_5']
survey[survey['Q3'] == 'South Korea']['Q7_Part_6']
survey[survey['Q3'] == 'South Korea']['Q7_Part_7']
survey[survey['Q3'] == 'South Korea']['Q7_Part_8']
survey[survey['Q3'] == 'South Korea']['Q7_Part_9']
survey[survey['Q3'] == 'South Korea']['Q7_Part_10']
survey[survey['Q3'] == 'South Korea']['Q7_Part_11']
survey[survey['Q3'] == 'South Korea']['Q7_Part_12']

survey_test = survey[survey['Q3'] == 'South Korea']

for i in range(1, 13):
    print(survey_test[f'Q7_Part_{i}'].value_counts())

korean = survey.loc[survey.Q3 == 'South Korea', :]
selected_cols = [col for col in survey.columns if col.startswith("Q7")]
temp = korean[selected_cols]

for i in temp:
    print(temp[i].value_counts())

temp.isna().sum().sort_values(ascending=False)[:5]

# Prudential Life Insurance Assessment

train = pd.read_csv('./train.csv')
train

train.iloc[:, :15].info()

selected_cols = [col for col in train.columns if col.startswith("Medical")]
selected_cols

train[selected_cols].info()

# train.isna().mean() > 0.7 # 결측치 비율
drop_cols = train.columns[train.isna().mean() > 0.7] # 결측치 비율이 70%가 넘는 columns
drop_cols

# 결측치 열 삭제
train.drop(columns=drop_cols, inplace=True)
train

# 각 columns별로 평균값으로 결측치를 채워줍니다.
train.fillna(train.mean(), inplace=True)
train

train.info()

train.Product_Info_2.value_counts()

from sklearn.preprocessing import LabelEncoder

encoder = LabelEncoder()
train.Product_Info_2 = encoder.fit_transform(train.Product_Info_2)
train

# numpy array는 데이터 타입이 동일하고, 크기가 똑같아야 한다.

v1 = np.array([1, 2, 3]) # vector arithmetic
v2 = np.array([-1, -2, 3])
v1 + v2

# 참고 : list는 concat(이어 붙인다)

# 첫번째 고객과 가장 유사한 고객을 찾자
# 유사한 = euclidean distance
def euclidean_distance(x, y):
    # x, y는 Numpy array
    # 1) x, y의 각 원소끼리 뺀다.
    # 2) 뺀 값을 제곱해서 다 더한다.
    # 3) 루트를 씌운다.
    diff = x - y # 1)
    square = np.square(diff) # 2)
    _sum = square.sum() # np.sum(square) # 2)
    distance = np.sqrt(_sum) # 3)

    return distance

v3 = np.array([0, 0])
v4 = np.array([3, 4])

euclidean_distance(v3, v4)

def manhattan_distance(x, y):
    diff = x - y
    _abs = np.abs(diff)
    distance = np.sum(_abs)
    return distance

v3 = np.array([0, 0])
v4 = np.array([3, 4])

manhattan_distance(v3, v4)

def cosine_distance(x, y):
    # 1) vector 12 norm
    # 2) 내적
    dot = x @ y # 내적 계산 연산자
    l2_x = np.sqrt(np.sum(np.square(x))) # L2 norm
    # l2_x = euclidean_distance(np.zeros(len(x)),x)
    # (3 - 0, 4 - 0) -> ((3 - 0)^2, (4 - 0)^2) 
    
    l2_y = np.sqrt(np.sum(np.square(y))) # 제곱 합하고 루트
    similarity = dot / (l2_x * l2_y)
    distance = 1 - similarity
    return distance.astype(np.float64) 

v5 = np.array([1, 1])
v6 = np.array([2, 2])
v7 = np.array([-1, -1])

cosine_distance(v6, v7)

train.iloc[0].values

# 첫번째 유저랑 가장 유사한 고객 찾기
# 1. L2
# 2. L1
# 3. cosine
target = train.iloc[0].values # numpy array

min_value = 123456789 # ?
min_idx = 1 # 첫번째 고객과 가장 유사해야하기에 1번을 제외하려고 설정함
for i in range(1, len(train)):
    l2 = euclidean_distance(target, train.iloc[i].values) # 첫번째 고객과 i번째 고객 사이의 거리
    if l2 < min_value:
        min_value = l2
        min_idx = i

print(f'{min_idx +1}번째 고객이 가장 유사한 고객입니다.')

# 첫번째 유저랑 가장 유사한 고객 top 5 찾기
# 1. L2
# 2. L1
# 3. cosine
target = train.iloc[0].values # numpy array

distances = []
for i in range(1, len(train)):
    l2 = euclidean_distance(target, train.iloc[i].values) # 첫번째 고객과 i번째 고객 사이의 거리
    distances.append(l2)

print(f'{min_idx +1}번째 고객이 가장 유사한 고객입니다.')

min_idx = np.argsort(distances)[:5] # top 5의 고객 index
min_idx

for i in min_idx:
    print(f'{i+1}번째 고객이 가장 유사한 고객 입니다.') # 0번째 고객이 없으니까

# Q. 3번째 고객 기준으로 가장 유사한 고객 3명을 찾는 코드 작성
# 유사도의 기준은 L1 distance

target = train.iloc[2].values # numpy array

distances = []
for i in range(len(train)):
    l1 = manhattan_distance(target, train.iloc[i].values) # 첫번째 고객과 i번째 고객 사이의 거리
    distances.append(l1)
    
min_idx = np.argsort(distances)[1:4] # top 5의 고객 index
for i in min_idx:
    print(f'{i+1}번째 고객이 가장 유사한 고객입니다.')
