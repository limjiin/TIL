머신러닝
- 정의
1) 데이터를 통해 머신이 '데이터관계(Weights)'를 학습하는 것 
2) Cost가 가장 낮을 때의 Weights를 찾는 것이다
3) 최적화 (Optimization) = 오차 최소화 + 일반화, 추상화 -
-> 데이터, 모델 
-> 모델을 데이터에 잘 맞게 변형 : 규제화

- 원리
1) weight 초기값을 설정한 다음 
2) 그 순간의 Cost 계산하고
3) 그 순간의 Cost 함수의 기울기를 계산해서 : Wt+1 <- Wt - @*G

선형 회귀 : 비교적 단순한 y = 10x

모델 복잡도 제한 = 학습 fit
-> 모델의 복잡도가 크면 과적합 가능성이 커진다
-> 수치 = weight의 크기 
-> 가장 낮을 때의 Cost = 오차 + lambda(비중) weight 크기
-> norm : L1(Lasso) L2(Ridge)

Linear Regression : 직선
-> 규제 : weight 개수가 많을 때 : 방정식보다 미지수가 많은 경우 해는 무수히 많다 : 방정식의 수 = 데이터의 수 : 미지수의 수 = weight의 수

회귀 -> 평가 
1) 오차
2) R2 score : 최댓값 1, 최솟값 0 : 최솟값은 오차와 분산이 같을 때
-> 오차 : 실제값 - 예측값
-> 분산 : 실제값 - 실제값들의 평균값
3) 즉, 예측을 실제값의 평균일 때

weight 가중치
coef 상관계수
x feature 중요도 : y = 10x + 2x
-> 숫자가 크면(10x) 영향이 적고, 숫자가 작으면(2x) 영향이 크다

단순하다
-> 설명 가능하다
-> 최적화 -> 오차최소화 -> 일반화

Wt+1 < Wt - @G
->  @ = learning_rate

Ridge Regression
-> weight의 절대값 자체가 작아진다
-> 규제를 쎄게 주면(alpha 값 크게) 과소적합 된다.

Elastic Regression
-> L1 ratio를 줄일수록 Ridge 스럽게, 늘릴수록 Lasso 스럽게
-> 1-ratio1 x^, ratio1 |x|

Ridge vs Lasso
-> cost : 오차 + w^ vs 오차 + |w|
-> 기울기 G : 오차' + |w| vs 오차' + C

-> 전반적으로 Ridge를 선호하지만, 필요에 따라서 규제를 강하게 걸어야 할 필요가 있을 때 Lasso를 사용한다

