Part.01 머신러닝의 개념과 종류
1. 머신러닝의 개념
무엇(x)으로 무엇(y)을 예측하고 싶다.
기계 학습 또는 머신 러닝은 인공 지능의 한 분야로, 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야
주어진 데이터를 통해 입력변수와 출력변수 간의 관계를 만드는 함수를 만드는 것
주어진 데이터 속에서 데이터의 특징을 찾아내는 함수를 만드는 것
머신 러닝으로 할 수 있는 것들
X : 고객들의 개인 정보 및 금융 관련 정보, Y : 대출 연체 여부
X : 상품 구매 고객 특성 정보 -> 군집화를 통한 고객 특성에 따른 세그멘테이션
X : SNS 데이터 및 뉴스 데이터 -> 소셜 및 사회 이슈 파악
함수 f(x) = Y
f를 구하기 위해 입력 변수와 출력 변수가 필요함
p개의 입력 변수가 있고, 출력 변수 Y가 있을 때, X라 하면 입력 변수와 출력 변수가 나타내는 식

2. 지도 학습과 비지도 학습
지도 학습
Y = f(x) 에 대하여 입력 변수(x)와 출력 변수(y)의 관계에 대해 모델링 하는 것(Y에 대해 예측 또는 분류)
회귀 : 입력 변수 X에 대해 연속형 출력 변수 Y를 예측
분류 : 입력 변수 X에 대해 이산형 출력 변수 Y를 예측
예 : 주식가격 예측, 공정 불량 여부 탐지
 비지도 학습
출력 변수가 존재하지 않고, 입력 변수 간의 관계에 대해 모델링
군집 분석 : 유사한 데이터끼리 그룹화
PCA : 독립변수들의 차원을 축소화
예 : 고객 segmentation
강화학습
수 많은 시뮬레이션을 통해 현재의 선택이 먼 미래에 보상이 최대가 되도록 학습
Agent가 action을 취하고 환경에서 보상을 받고 이 보상이 최대가 되도록 최적의 action을 취하는 것
예 : 알파고

3. 머신러닝의 종류
선형 회귀분석
독립 변수와 종속 변수가 선형적인 관계가 있다는 가정 하에 분석
직선을 통해 종속 변수를 예측하기 때문에 독립 변수의 중요도와 영향력을 파악하기 쉬움
단 비선형 관계는 파악하기 어려움
의사결정나무(Decision Tree)
독립 변수의 조건에 따라 종속 변수를 분리
이해하기 쉬우나 overfitting이 잘 일어남
KNN(K-Nearest Neighbor)
새로 들어온 데이터의 주변 K개의 데이터의 class로 분류하는 기법
Neural Network
입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트 하면서 학습
SVM(support vector machine)
class 간의 거리가 최대가 되도록 decision boundary를 만드는 방법
Ensemble Learning
여러 개의 모델(classifier or base learner)을 결합하여 사용하는 모델
K-means clustering
Label 없이 데이터의 군집으로 k개로 생성

4. 딥러닝의 주요 모델
참고 : Neural Network
입력, 은닉, 출력층으로 구성된 모형으로서 각 층을 연결하는 노드의 가중치를 업데이트 하면서 학습
Overfitting이 심하게 일어나고 학습기간이 매우 오래걸림
Deep Learning
다층의 layer를 통해 복잡한 데이터의 학습이 가능토록 함
알고리즘 및 GPU의 발전이 딥러닝의 부흥을 이끔
다양한 형태로 발전(CNN, RNN, AutoEncoder 등)
다양한 분야로 발전
네트워크 구조의 발전(ResNET, DenseNET 등)
네트워크 초기화 기법
다양한 activation function
Generalization, overfitting
Semi-supervised learning, Unsupervised learning
GAN(Generative Adversarial Network)
Data를 만들어내는 Generator와 만들어진 data를 평가하는 Discriminator가 서로 대립적으로 학습해가며 성능을 점차 개선해 나가자는 개념
-Discriminator를 학습시킬 때는 D(x)가 1이 되고 D(G(z))가 0이 되도록 학습시킴(진짜 데이터를 진짜로 판별하고, 가짜데이터를 가짜로 판별할 수 있도록)
-Generator를 학습시킬 때는 D(G(z))가 1이 되도록 학습시킴(가짜데이터를 discriminator가 구분 못하도록 학습, discriminator를 헷갈리게 하도록)
강화 학습(Reinforcement Learning)
Q-learning : 현재 상태에서 먼 미래까지 가장 큰 보상을 얻을 수 있는 행동을 학습
Q-learning + Deep Learning : DQN(Deep Reinforcement Learning)
더 효율적으로 빠르게 학습 할 수 있는 강화학습 모델
Action이 continuous한 경우
Reward가 매우 희박(sparse)한 경우
Multi agent 강화학습 모델

마무리 : 머신러닝 -> 딥러닝 -> 이미지, 텍스트, Generalization -> GAN, Reinforcement Learning

5. 모형의 적합성 평가 및 실험 설계
모형의 적합성을 평가하는 방법
모형의 복잡도에 따른 학습 집합의 MSE(회색)와 검증 집합의 MSE(빨간색)의 변화는 아래 그림과 같음
학습 집합의 MSE는 복잡한 모형일수록 감소하지만, 학습 데이터가 아닌 또 다른 데이터(검증 데이터)의 MSE는 일정 시점 이후 증가
증가하는 원인은 왼쪽 그림과 같이 모형이 학습 집합에 과적합되기 때문
데이터 분할
과적합을 방지하기 위해 전체 데이터를 학습 데이터, 검증 데이터, 테스트 데이터로 나누며 보통 비율은 5:3:2로 정함
데이터 분할 > 모형 학습 > 모형 선택 > 최종 성능 지표 도출
K-fold 교차 검증(cross validation)
모형의 적합성을 보다 객관적으로 평가하기 위한 방법
데이터를 K(주로 5 또는 10)개 부분으로 나눈 뒤, 그 중 하나를 검증 집합, 나머지를 학습 집합으로 분류
위 과정을 K번 반복하고 K개의 성능 지표를 평균하여 모형의 적합성 평가
LOOCV(Leave-one-out cross validation)
데이터의 수가 적을 때 사용하는 교차검증 방법
총 n개의 모델을 만드는데, 각 모델은 하나의 샘플만 제외하면서 모델을 만들고 제외한 샘플로 성능 지표를 계산함. 도출된 n개의 성능 지표를 평균 내어 최종 성능 지표를 도출
마무리
데이터가 적은 경우 : LOOCV
데이터가 애매하게 많은 경우 : K-Fold 교차 검증
그 외 : 데이터 분할 : 데이터 분할

6. 모형의 적합성 평가 및 실험(데이터분석과정)
데이터 분석 과정
raw 데이터 -> 전처리 된 데이터 -> 실험설계 -> Model
전처리 : Raw 데이터를 모델링 할 수 있도록 데이터를 병합 및 파생 변수 생성
실험 설계
test 데이터는 실제로 우리가 모델을 적용 한다는 가정 하에 test 데이터 없이 실험 설계
Train, Validation 데이터에 test 정보는 없어야 함

7. 과적합(Overfitting)이란
과적합이란
복합한 모형일수록, 데이터가 적을수록 과적합이 일어나기 쉬움
아래 그림은 회귀분석에서 고차향을 넣었을 때 만들어지는 직선
과적합은 data science 뿐만 아니라 AI 전반적으로 매우 큰 이슈
분산과 편파성의 트레이드 오프
모형 f^(x)로 모집단의 전체 데이터를 예측할 때 발생하는 총 error를 계산하면 reducible error와 irreducible error로 표현되며, reducible error는 다시 분산과 편파성으로 구성
분산 : 전체 데이터 집합 중 다른 학습 데이터를 이용했을 때, f^이 변하는 정도
편파성 : 학습 알고리즘에서 잘못된 가정을 했을 때 발생하는 오차
복잡한 모형 f^(x)을 사용하여 편파성을 줄이면, 반대로 분산이 커짐
예측값과 실제값은 분산과 예측할 수 있는 정도와 어쩔 수 없이 예측할 수 있는 오차 범위로 이루어져 있다.
적절한 모형의 선택과 실험 설계를 통한 과적합 방지(표본은 모집단을 완벽하게 대표하지 않으니까)

Part.02 회귀분석
1. 회귀분석을 위한 통계 : 수학적 개념 이해 - 통계학
모집단(population) < (추정 추론) - (표본 추출) > 표본(sample)
모집단 : 연구의 대상이 되는 모든 개체들을 모은 집합
일반적으로 시간적, 공간적 제약으로 인해 모집단 전체를 대상으로 한 분석은 불가능
표본 : 모집단의 일부분의 관측값들
모집단 : 모집단의 요약값 < (추정 추론) - 표본 : 통계량
모수(Parameter) : 수치로 표현되는 모집단의 특성
통계량(Statistic) : 표본의 관측값들에 의해 결정되는 양
자료의 종류
수치형(양적 자료)
연속형(몸무게, 키) : 값 사이에 새로운 값을 넣을 수 있음
이산형(전화 통화 수) : 분절
범주형(질적 자료)
순위형(학점)
명목형(성별) : 순위 없음

반응변수
설명변수
범주형
연속형
범주형(이산형)
범주형 자료 분석
(카이스퀘어 검정)
로지스틱 회귀분석
연속형
분산분석
회귀분석

자료의 요약 - 그림, 표
범주형 자료 : 도수 분포표, 막대/원형 그래프
연속형 자료 : Box plot, 히스토그램(Histogram)

2. 수학적 개념 이해 : 기술통계량, 추정량
자료의 요약 : 수치
모집단 개체의 수 : N
중심 경향값 (대표값)
평균(값의 변화에 따라 영향을 받음)
중앙값 : 크기 순으로 정렬시켜 중앙에 위치한 값(값의 변화에 영향이 적음)
최빈값 : 가장 자주 나오는 값
산포도(퍼진 정도)
분산
사분위수 범위 : 전체 관측값을 크기순으로 정렬했을 떄 중앙에 위치한 50%의 관측치가 가지는 범위
정규 분포
자연과학 현상을 설명할 때 가장 널리 쓰이는 분포
위치는 평균에 의해, 모양은 분산에 의해 결정
분포도
왜도 : 분포의 비대칭 정도, Left-skewed를 Negative skewed로 표현하기도 함
첨도(Kurtosis)
분포의 꼬리 부분의 비중에 대한 측도
Ks = 0 : 뾰족한 정도가 정규 분포와 동일
통계학이란 ? 리뷰
모수
통계량
추정량
통계량, 추정량
추정량의 종류 (표본 관측치의 개수 : n)
표본 평균
표본 분산

3. 수학적 개념 이해 : 확률
확률
확률 실험(Random experiment) : 다음과 같은 속성을 지닌 관찰이나 인위적인 실험
결과를 미리 알 수 없다
실험에서 일어날 수 있는 모든 결과는 사전에 알려져 있다
이론적으로는 실험을 반복할 수 있다
표본공간(Sample space): 모든 결과들의 모임
근원사건(Sample outcome) : 표본 공간의 원소
사건(Event) : 표본 공간의 부분집합. 근원사건의 집합
배반 사건(Mutually exclusive events) : 서로 교집합이 공집합인 사건
예 : 주사위, 동전 던지기
확률 값
어떠한 사건이 일어날 가능성의 정도
근원사건이 일어날 가능성이 동일할 때의 계산
확률의 공리
어떠한 사건들이 서로 배반사건일 때, 이 사건들의 합 사건의 확률은 각각의 사건이 일어날 확률의 합과 같다
조건부 확률
사건 B에 대한 정보가 주어졌을 때, 사건 A의 교정된 확률
B가 주어졌을 때 사건 A의 조건부 확률
독립
사건 A와 B가 서로에게 아무런 영향을 미치지 않을 때
확률 변수, 확률 분포
확률 변수 : 각각의 근원 사건들에 실수 값을 대응시키는 함수
확률 분포 : 확률 변수에서 확률값으로의 함수. 주로 f(x)로 표기
확률 변수의 기대값 : 확률 변수의 중심 경향 값. 흔히 평균
확률 변수의 분산
공분산
두 개의 확률 변수 X, Y가 상호 어떤 관계를 가지며 변화하는 가를 나타내는 척도
X, Y가 독립이면 Cov(X, Y) = 0
상관계수
공분산은 X, Y단위의 크기에 영향을 받음
상관계수는 공분산을 단위화한 값
이산형 확률분포
베르누이 시행
실험의 결과 범주가 2가지인 경우(성공/실패)
이항분포
성공확률이 p인 베르누이 시행을 독립적으로 n번 시행했을 때 성공한 횟수의 분포
다항 분포
다항 시행 : 1회의 시행결과로 나올 수 있는 범주가 3개 이상이 되는 확률 시험
K개 범주의 다항 시행을 n번 반복했을 때, 각 범주가 나타나는 횟수의 분포
포아송분포
주어진 단위 구간 내에 평균적으로 발생하는 사건의 횟수가 정해져 있을 때, 동일 단위에서의 발생 횟수
[O사건의 평균 발생횟수는 단위 구간에 비혜
두 개 이상의 사건이 동시에 발생할 확률은 0에 가깝다
어떤 단위구간의 사건 발생은 다른 단위 구간의 발생으로부터 독립적
100페이지 안에 있는 오타의수, 1시간 동안 걸려온 전화의 수
지수분포
정규분포
표준정규분포 : 평균이 0이고 분산이 1인 정규분포

4. 수학적 개념 이해 : 추정, 추론
통계적 추론
점 추정(point estimation)
추정량을 통해 모수를 추정
구간 추정(interval estimation)
일정 신뢰수준 하에서 모수를 포함할 것으로 예상되는 구간을 제시
신뢰 수준(1-a)과 구간의 길이는 반비례
통계적 검정
대립가설
입증하여 주장하고자 하는 가설
귀무가설
대립가설의 반대가설
귀무가설이 아니라는 충분한 증거를 데이터로부터 보임으로써 대립가설을 입증
귀무가설 하에서 통계량의 분포를 아는 것이 검정의 핵심
오류의 종류
1종 오류 : 귀무가설이 맞을 때, 귀무가설을 기각하는 오류
2종 오류 : 귀무가설이 틀렸을 때 귀무가설을 기각하지 않는 오류
검정통계량, 기각역
검정통계량
표본에서 구해낼 수 있는 함수. 이 값을 기준으로 귀무가설 기각여부를 결정
기각역
검정통계량이 취하는 구간 중 귀무가설을 기각하는 구간
단측 검정
양측 검정
유의 확률(P-value)
주어진 검정통계량의 값을 기준으로 해당 값보다 대립 가설을 더 선호하는 검정통계량 값이 나올 확률
이 값이 유의수준보다 낮으면 귀무가설을 기각
참고 : 기각역
검정통계량과 관련된 분포
Z 통계량
t 분포 : 자유도가 커질수록 정규분포에 근사
카이제곱 분포 : 확률변수의 제곱합으로 이루어진 통계량
F 분포
두 확률변수가 자유도이고, 서로 독립인 카이제곱 분포를 따를 때
확률변수의 제곱합을 관측치로 나눈 것의 비율로 이루어진 통계량

5. 수학적 개념 이해 : 미분의 개념
평균 변화율
순간 변화율
평균 변화율의 극한 값
b점이 a점으로 한없이 가까워질 때, a점에서의 순간 변화율
a점에서의 접선의 기울기
미분의 개념
다항함수의 미분 및 미분 기본 공식
곱의 미분
합성함수 미분
지수함수 미분
로그함수 미분
미분의 활용
극대값, 극소값
미분값은 접선의 기울도함수를 통하여 미분가능한 함수의 극대값, 극소값을 구할 수 있음
Likelihood
Likelihood function(가능도함수/우도함수)
확률분포함수 : 모수를 알 때, 확률변수의 실현값을 예측하고자 함
종류
확률밀도함수 : 연속형 확률변수의 확률 분포함수
확률질량함수 : 이산형 확률변수의 확률 분포함수
누적분포함수 : 누적 확률 분포함수
가능도함수 : 확률 변수의 실현값을 알 때, 데이터가 있을 때 모수를 추정하고자 함
미분의 활용 : MLE
MLE(Maximum Likelihood Estimator) : Likelihood를 최대로 만드는 모수의 값

6. 수학적 개념 이해 : Matrix 정의 및 성질
Matrix 표기법
Matrix
Vector : 행 또는 열의 수가 1인 경우, 전자는 row vector 후자는 column vector
Transpose and symmetric
Matrix
Scalar : 1 by 1 matrix
Identity matrix
Diagonal matrix
Equality : 모든 i, j에 대해
합, 차의 성질
곱 : 상수배, 행렬곱
내적 : Row vector 와 Column vector의 곱
행렬 곱의성질
Trace
행렬식 (determinant) |A| 구하기
2 by 2 matrix
역행렬(Inverse)
Idempotent : AA = A

7. Matrix 미분
미분 표기법의 종류
Matrix 미분을 헷갈리게 하는 이유 : 서로 다른 표기법이 존재
대부분 책에서 명시하지 않고 사용하기에 두 표기법의 개념을 모두 알아두는 것이 좋은
Numerator layout
미분 당하는 변수 혹은 함수를 기준으로 결과의 형태를 표기
Denumerator layout
미분을 하는 변수 혹은 함수를 기준으로 결과의 형태를 표기
핵심 : 의도한 미분을 수행했을 때 결과값의 차원
Scalar를 vector로 미분
Vector를 vector로 미분
주요 미분 결과 간편 활용 방법
내적 형태
미분하면 a 꼴이 나올 것. 스칼라 - 벡터의 미분 > 분모 차원의 반대. 1 X p 만들어주기
Matrix - vector 곱 형태(Linear from)
미분하면 a 꼴이 나올 것. 벡터 - 벡터의 미분 > 분자 차원 유지. A의 행차원 같이 만들어주기
제곱 형태 (Quadratic form)
미분하면 (A + At)x 꼴이 나올 것. 스칼라 - 벡터의 미분 > 분모 차원의 반대. 1 X p 만들어주기
회귀분석에 적용

8. 회귀분석이란
지도 학습(supervised learning)
Y = f(x) 에 대해 입력 변수(x)와 출력 변수(y)의 관계에 대하여 모델링하는 것(Y에 대해 예측 또는 분류하는 문제)
회귀(regression) : 입력 변수 x에 대해 연속형 출력 변수 y를 예측
분류(classification) : 입력 변수 x에 대해서 이산형 출력 변수 y(class)를 예측
입력 변수인 x의 정보를 활용하여 출력 변수인 y를 예측하는 방법
회귀분석 중 간단한 방법으로는 선형회귀분석(좌측 그림)이 있으며, 이를 바탕으로 더 복잡한 회귀분석(우측 그림)이 개발
대부분의 분류 모델(SVM, Decision Tree 등)로도 회귀가 가능함
단순 선형 회귀분석
입력 변수가 x, 출력 변수가 y일 때, 단순 선형 회귀의 회귀식은 검은 선으로 나타낼 수 있음
어떻게 추정할까 ? 직선과 데이터의 차이가 평균적으로 가장 작아지는 직선

9. 회귀계수추정
실제 값과 우리가 추정한 값의 차이가 적으면 적을 수록 좋은 것
실제 값과 우리가 추정한 값의 차이를 잔차라고 하며 이를 최소화 하는 방향으로 추정
잔차의 제곱합
굳이 최소화 시키는 이유?
잔차의 합이 0이 되는 해는 무수히 많음(유일한 해를 찾지 못함)
잔차의 절대값의 합은 미분이 불가능한 형태
잔차의 제곱 합은 미분이 가능한 형태로 유일한 해를 찾을 수 있음

10. 회귀계수의 의미
회귀 계수의 해석
B1의 해석 : x1이 1단위 증가할때마다 y가 B1만큼 증가한다.
선형 회귀의 정확도 평가
선형 회귀는 잔차의 제곱합(SSE : Error sum of squares)을 최소화하는 방법으로 회귀 계수를 추정
즉 SSE가 작으면 작을수록 좋은 모델
MSE(Mean Squared Error)는 SSE를 표준화한 개념
회귀 분석은 결국 Y의 변동성을 얼마나 독립변수가 잘 설명하느냐가 중요
변수가 여러 개일 때 각각 Y를 설명하는 변동성이 크면 좋은 변수 > p-value 자연스레 낮아짐
R = SSR / SST

11. 회귀계수에 대한 검정
단순 선형 회귀분석의 검정
표준오차
표본분포
귀무가설 : 채택하고 싶지 않은 가설, 기각 하기 너무 쉬운 가설. 변수가 추가 되면 추가 될수록 기각하기 쉬워진다.
대립가설 : 채택하고 싶은 가설
신뢰구간

12. 다중 선형 회귀분석
회귀계수를 추정하는 것은 단순 선형 회귀분석과 동일하게 SSE를 최소화하는 방향으로 추정
행렬
F-검정 : SSR / MSE(분자, 분모 모두 제곱합의 형태) : 제곱합의 형태로 검정을 하는 F 검정의 특성상 변수가 추가되면 자연스레 기각하기 쉬워진다.

13. 다중공선성(Multi)
독립변수들이 강한 선형관계에 있을 때 다중공선성이 있다고 한다.
변수들 간의 다중공선성이 있다고 한다. 잘못된 변수 해석, 예측 정확도 하락 등을 야기시킨다.
다중공선성을 진단하는 방법
VIF(Variance inflation factor), 변수들간의 Correlation 등으로 진단
다중공선성을 해결하는 방법
feature selection : 중요 변수만 선택하는 방법
변수를 줄이지 않고 활용하는 방법
상관행렬(correlation matrix) : 상관행렬 및 산점도를 보고 판단
다중공선성을 근본적으로 해결하는 방법은 아직 없다.
머신러닝 기법은 기본적으로 학습 데이터 내에서 예측력을 높이기 위해 최대한 많은 변수를 활용하려 함

14. 회귀모델의 성능 지표
R 스퀘어 : 변수가 증가하면 증가할수록 R스퀘어는 자연스레 증가
Adjusted R 스퀘어
변수 수가 증가하면 자연스레 SSR이 증가하고 R2 또한 자연스레 증가함.
회귀분석의 성능지표로서 R2가 큰 의미가 없음
R2에 변수 수 만큼 penalty를 주는 지표
AIC(Akaike information criterion)
모델의 성능지표로서 MSE에 변수 수만큼 penalty를 주는 지표
일반적으로 회귀분석에서 Model Selection 할 때 많이 쓰이는 지표
BIC(Bayes Information Criteria)
AIC의 단점은 표본 n이 커질 때 부정확해짐
이를 보완한 지표가 BIC

15. 모형의 성능 지표(주로 다루는 성능 지표)
MSE(Mean Squared Error)
f가 제대로 추정 되었는지 평가하기 위해, 예측한 값이 실제 값과 유사한지 평가하는 척도가 필요함
MSE는 실제 종속 변수와 예측한 종속 변수 간의 차이
MSE가 작을수록 좋지만, MSE를 과도하게 줄이면 과적합의 오류를 범할 가능성이 있음
MAPE
f가 제대로 추정 되었는지 평가하기 위해, 예측한 값이 실제 값과 유사한지 평가하는 척도가 필요함
MAPE는 퍼센트 값을 가지며 0에 가까울수록 회귀 모형의 성능이 좋다고 해석할 수 있음
0~100% 사이의 값을 가져 이해하기 쉬우므로 성능 비교 해석이 가능
정확도(Accuracy)
정확도는 전체 데이터 중에서 모형으로 판단한 값이 실제 값과 부합하는 비율
분모는 전체 데이터가 되고 분자는 모형이 실제 정상을 정상으로 그리고 실제 이상을 이상으로 옳게 분류한 데이터
Accuracy = 옳게 분류된 데이터의 수 / 전체 데이터의 수
정밀도, 재현율, 특이도
분류 모형의 목적에 따라 다양한 지표를 볼 수 있음
정밀도(precision) = 옳게 분류된 불량 데이터의 수 / 불량으로 예측한 데이터 : 분류 모형이 불량으로 진단하기 위해 얼마나 잘 작동했는지
재현율(recall) = 옳게 분류된 불량 데이터의 수 / 실제 불량 데이터 : 불량 데이터 중 실제 불량이라고 진단한 제품의 비율(진단 확률)
특이도(specificity) = 옳게 분류된 정상 데이터의 수 / 실제 정상 데이터 : 분류 모형이 정상을 진단하기 위해 잘 작동하는지를 보여주는 지표
G-mean, F1 measure
실제 데이터의 대표적인 특성에는 불량(이상) 데이터를 탐지하는 것이 중요하다는 점과 이러한 불량 데이터는 매우 소수의 데이터라는 점
실제 데이터의 특성상 정확도 보다는 제1종 오류와 제 2종 오류 중 성능이 나쁜 쪽에 더 가중치를 주는 G-mean 지표나 불량에 관여하는 지표인 정밀도와 재현율만 고려하는 F1 measure가 더 고려해볼 수 있는 지표임
ROC(Receiver Operating Characteristics) curve, AUC
가로축을 1 - 특이도(specificity), 세로축을 재현율(recall)로 하여 시각화한 그래프를 ROC curve라고 함
이때 ROC curve의 면적을 AUC라고 함
