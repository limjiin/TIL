1. 통계 (statistics)
: 데이터(측정값)에 대해 잘 모른다 => 데이터에 대해 정보를 얻기 위해 사용하는 개념

- 왜 ? 
1) 데이터의 의미를 잘 모르는 경우(예: 도메인 지식을 많이 필요로 하는 경우) 
2) 양이 많은 경우(예 : 국영수 점수 경향 파악을 하려는데 학생이 60만명인 경우) 
3) 측정 자체의 오류(예 : 설문조사를 할 때 사람들이 막 적는 경우, sensing 자체 오류)

2. 기술통계 (descriptive statistics)
: 수집한 데이터를 분석하여 대상들의 속성을 파악하는 통계 방법 (또는 수치값들)

- 중심경향값 : 전체 자료를 대표할 수 있는 수치들 (예:  평균, 최빈값)
1) 평균 : 전체 자료가 가지는 수치들의 총합을 전체 자료 수로 나눈 수치
2) 중앙값 : 최대값과 최소값의 한가운데 수치
3) 최빈값 : 가장 많은 빈도를 가진 수치
4) 사분위수 : Xn/4, Xn/2, X3/4n

- 분산도 : 전체 자료가 얼마나 퍼져 있는지를 알 수 있는 수치들 (예: 분산)
1) 분산 : 각 자료가 평균으로 부터 떨어진 정도를 제곱한 수치들의 평균
2) 표준편차 : 분산의 제곱근

- 상관계수 : 두 변수 간의 관계의 크기 (예: 피어슨 상관계수)
1) 공분산 : 두 변수가 함께 각자의 평균으로부터 멀어지는 정도. 한 변수가 자신의 평균으로부터 멀어질 때, 다른 변수가 자신의 평균으로부터 멀어지는 정도를 의미
2) 상관계수 : 두 변수 간의 관계로, 하나의 변수가 변화함에 따라 다른 변수가 변화하는 정도를 의미 [-1, 1] (예 : 부동산 가격 ~지하철역과의 거리)
(1) 양의 상관계수(0.3 ↑) : 양의 상관관계를 가진다
(2) 음의 상관계수(-0.3 ↓) : 음의 상관관계를 가진다.
단, 상관계수가 있다고 해서 인과관계를 가지는 것은 아니다. 
예) 아이스크림 판매량과 상어의 물린 사람 수
반면, 상관계수가 0.01이지만 관계 또 영향이 있는 경우도 있다. 

- 회귀계수 : 독립변수(x)가 종속변수(y)에 미치는 영향의 크기 (예 : 선형회귀)
1) 오차(error)를 최소화하는 방향으로 직선이 생성됨
예1) Y = aX + b + e(오차) : y는 알지만, x는 모르는 값 : a(기울기)랑 b(y절편)가 상수일 때
데이터(x, y)
예2) x -> f -> y 로 예측하는 것. f : 머신러닝, 모델링, unseen data에 대한 예측 -> linear model -> linear regeression
예3) y^(모델링한 결과) = y(실제 정답) + e(error) 

왜 통계를 하는가? 1억개의 데이터를 외울 수는 없지만, 찾고는 싶으니까 -> DB에 데이터 저장 -> 모르니까 -> 머신러닝, 모델링

3. 추리통계 (Inferential Statistics)
: 수집한 데이터를 확인하고 데이터의 표본이 되는 값을 찾아서, 기술통계를 이용하여 모집단의 속성들을 유추하는 통계 기법

1) 표본 집단(표본 집단의 통계량) : training -(추정, N = 30 이상)> 모집단(모집단의 통계량) : test data
2) 설문조사 : 일부의 사람 1. 얼마나 데이터를 모아야 하는가? -> 분석결과 : 전체 집단(모집단) 2. 분석결과를 얼마나 믿을 수 있는가?
3) 표본 집단의 조건 (1) unbiased : 특정 데이터 볼 수 있음 (2) 모집단과 같은 특성 : 비슷한 통계량을 가지고 있어야 함

4. 코드로 풀어보는 기초 통계

##### statsmodel과 pandas로 풀어보는 기초통계 실습

## 라이브러리 불러오기
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import warnings
import platform
from matplotlib import font_manager, rc

## 운영체제별 글꼴 세팅

path = "c:/Windows/Fonts/malgun.ttf"
if platform.system() == 'Darwin':
    font_name = 'AppleGothic'
    rc('font', family='AppleGothic')
elif platform.system() == 'Windows':
    font_name = font_manager.FontProperties(fname=path).get_name()
    rc('font', family=font_name)
else:
    font_name = font_manager.FontProperties(fname="/usr/share/fonts/nanumfont/NanumGothic.ttf")
    rc('font', family="NanumGothic")

warnings.simplefilter(action='ignore')

## 파일 불러오기
train = pd.read_csv('./energy/train.csv', encoding='cp949')
test = pd.read_csv('./energy/test.csv', encoding='cp949')
submission = pd.read_csv('./energy/sample_submission.csv', encoding='cp949')

# Q. 주어진 데이터의 column들 중 가장 넓은 분포를 가진 column은 무엇인가요?
round(train.describe(), 1)
# 전력사용량 : min-max, 표준편차가 가장 심함

# feature scaling -> 정확한 비교를 위해서 모든 데이터의 수치 범위(scale)를 0과 1 사이로 맞춰줍니다.
# x' = (x - x_min) / (x_max - x_min) (min-max scaling)
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(train.drop(columns='date_time', axis=1))
scaled_data

temp = pd.DataFrame(data = scaled_data, columns = L, index=train.index)
temp

L = train.columns.to_list()
L.remove('date_time')

round(temp.describe(), 1)

##### Feature EDA

import seaborn as sns

plt.figure(figsize=(14, 6))
sns.countplot(data=train, x='num')
plt.show()

##### Numeric Feature EDA
- 전력사용량, 기온, 풍속, 습도, 강수량, 일조량

## Hist plot
plt.figure(figsize=(16, 8))
sns.histplot(data=train, x='풍속(m/s)', bins=30)
plt.show();

plt.figure(figsize=(16, 8))
sns.histplot(data=train, x='기온(°C)', bins=30)
plt.show();

plt.figure(figsize=(16, 8))
sns.histplot(data=train, x='습도(%)', bins=30)
plt.show();

plt.figure(figsize=(16,8))
sns.histplot(data=train, x="강수량(mm)", bins=30)
plt.show();

plt.figure(figsize=(16,8))
sns.histplot(data=train, x="전력사용량(kWh)", bins=30)
plt.show();

plt.figure(figsize=(16,8))
sns.histplot(data=train, x="일조(hr)", bins=30)
plt.show();

## Box plot
plt.figure(figsize=(16,8))
sns.boxplot(data=train)
plt.show();

plt.figure(figsize=(16,8))
sns.boxplot(data=temp)
plt.show();

## Heatmap

corr = train.corr()

plt.figure(figsize=(16,8))
sns.heatmap(corr, square=True, annot=True, fmt=".4f", cmap='spring')
plt.show()

# 1번 건물에 대해 heatmap을 찍어보세요
building1 = train.loc[train.num == 1, :]
corr1 = building1.corr()

plt.figure(figsize=(16,8))
sns.heatmap(data=corr1, annot=True, fmt='.4f', square=True)
plt.show()


# 1) feature engineering
train.drop(columns='date_time', axis=1, inplace=True) # 시계열 분석을 안할거라서
train_ohe = pd.get_dummies(data=train, columns=['num'])

# 정규화 : drop_duplocate
building_info = train[['num', '비전기냉방설비운영', '태양광보유']].drop_duplicates()
building_info

# 건물 정보 결측치 처리
test.drop(columns=['비전기냉방설비운영', '태양광보유'], inplace=True)
test = pd.merge(test, building_info, on='num')

# 2) Test data 결측치 처리
# 보간법(interpolate)을 이용해서 numeric feature를 결측치 처리
test.interpolate(method='linear')

# 3) Test data feature engineering
test.drop(columns='date_time', inplace=True)
test_ohe = pd.get_dummies(data=test, columns=['num'])
test_ohe

test_ohe = test_ohe.interpolate(method='linear')

# X(features) ------------f--------------> y(target)
# f : linear regression
# scikit-learn을 이용해서 linear regression
from sklearn.linear_model import LinearRegression

X = train_ohe.drop(columns='전력사용량(kWh)') # independent variable
y = train_ohe['전력사용량(kWh)'] # dependent variables
print(X.shape, y.shape)

model = LinearRegression()
model.fit(X, y)

model.intercept_ # b == 회귀계수

model.coef_ # W == 회귀계수

pred = model.predict(test_ohe) # 예측한 전력사용량

submission['answer'] = pred
submission
