1. 지도학습 모델의 핵심 개념
지도학습
컴퓨터에게 입력과 출력을 주고, 입력과 출력 간 관계를 학습하여 새로운 입력에 대해 적절한 출력을 내도록 하는 기계학습의 한 분야
입력을 특징 혹은 특징 벡터 라고 하며, 출력을 라벨이라고 함
라벨이 범주형 변수면 분류라고 하며, 연속형 변수면 예측 혹은 희귀라고 함
과적합
지도학습 모델은 학습 데이터를 분류하고 예측하는 수준으로, 학습에 사용되지 않은 데이터도 정확히 분류하고 예측하리라 기대하며, 이러한 기대가 충족되는 경우 일반화되었다고 함
모델이 너무 복잡해서 학습 데이터에 대해서만 정확히 분류하고 예측하는 모델을 과적합 되었다고 하며, 반대로 너무 단순해서 어떠한 데이터에 대해서도 부적합한 모델을 과소적합되었다고 함
과적합과 과소적합에 영향을 끼치는 주요 인자로는 모델의 복잡도, 샘플 수 , 차원의 크기 등이 있음
데이터 분할
과적합된 모델을 좋게 평가하는 것을 방지하기 위해서, 데이터를 학습 데이터와 평가 데이터로 분할함
데이터 > 데이터 분할(학습데이터, 평가 데이터) > 학습데이터 > 탐색 전처리 모델 학습 > 모델 > 전처리 및 모델 적용 > 평가 데이터 > 평가 결과 도출 > 평가 결과
학습 데이터와 평가 데이터가 지나치게 유사하거나 특정 패턴을 갖지 않도록 분할해야 함
파라미터와 하이퍼 파라미터
하이퍼 파라미터는 일종의 사용자 옵션으로, 모델 성능에 직접적으로 영향을 끼치므로 자세한 데이터 탐색 결과를 바탕으로 선택해야 함

구분
파라미터
하이퍼 파라미터
정의
모델 내부에서 결정되는 변수
파라미터에 영향을 주는 파라미터
예시
신경망의 가중치, SVM의 가중치
신경망의 은닉층 구조, SVM의 커널
추정
비용 함수를 최소화하는 값으로 미리 정의된 컴퓨터 연산을 통해 추정
사용자가 직접 설정하며, 최적의 설정 방법은 없고, 휴리스틱한 방법이나 경험에 의한 설정이 대부분임


이진 분류 모델 평가 : 혼동 행렬
이진 분류 : 클래스 변수의 상태 공간이 크기가 2인 분류
혼동 행렬 : 분류 모델을 평가하는 데 사용하는 표
Positive class : 분석의 관심 대상 (보통 1로 설정)
Negative class : 분석의 관심 대상 외 (보통 0이나 -1로 설정)



예측값 Predicted Class
Positive
Negative
실제값
Actual Class
Positive
TP
FN
Negative
FP
TN


각 지표의 한계 때문에, 가능한 여러 지표를 사용하여 모델을 평가해야 함
정확도 : TP + TN / TP + FN + FP + TN
정밀도 : TP / TP + FP
재현율 : TP / TP + FN
F-1 score : 2 * Pre * Rec / Pre + Rec

다중 분류 모델 평가
다중 분류 : 클래스 변수의 상태 공간이 크기가 3 이상인 분류
각 클래스를 긍정으로 간주하여 평가 지표를 계산한 뒤, 이들의 산술 평균이나 가중 평균으로 평가

예측 모델 평가
대표적인 예측 모델 평가 지표로 루트 평균 제곱 오차(root mean squared error RMSE)와 평균 절대 오차(mean absolute error MAE)가 있으며, 두 지표 모두 값이 작을수록 좋음
RMSE와 MAE를 정확히 평가하려면 해당 분야의 도메인 지식이나 클래스 변수의 스케일을 고려해야 함


2. 모델 개발 프로세스
프로세스
: 문제 정의 > 데이터 수집 > 데이터 탐색 > 데이터 전처리 > 모델링 > 모델 평가 > 결과 보고서 작성
문제 정의
전체 프로세스 가운데 가장 중요한 단계로, 명확한 목적 의식을 가지고 프로세스를 시작해야 함
과업 종류 결정, 클래스 정의, 도메인 지식 기반의 특징 정의, 사용 데이터 정의
데이터 수집
문제 정의에서 정의한 데이터를 수집하는 단계로, 크롤링, 센서 활용, 로그 활용 등으로 데이터를 수집
기업내 구축된 DB에서 SQL을 통해 추출하는 경우가 가장 많으며, 이때는 클래스를 중심으로 수집
데이터 탐색
데이터가 어떻게 생겼는지를 확인하며, 프로세스를 구체화하는 단계
데이터 탐색 단계에서 변수별 분포, 변수 간 상관성, 이상치와 결측치, 변수 개수, 클래스 변수 분포 등을 확인하며 이 탐색 결과는 데이터 전처리 및 모델 선택에 크게 영향을 미침
데이터 전처리
원활한 모델링을 위해 데이터를 가공하는 단계
결측 값 처리, 데이터 통합, 이상치 제거, 재샘플링, 특징 선택, 더미 변수 생성
모델링
모델 선택 : 데이터 특성, 성능, 설명력 등을 기준으로 모델 선택 
하이퍼 파라미터 설정 : 모델의 성능을 결정짓는 하이퍼 파라미터를 설정
모델 학습 : 모델에 포함된 파라미터를 추정
모델 평가
분류 모델의 대표적인 지표 : 정확도, 정밀도, 재현율, F1 점수
예측 모델의 대표적인 지표 : 평균 제곱 오차, 평균 절대 오차, 평균 절대 퍼센트 오차
잘못된 평가를 피하기 위해, 둘 이상의 평가 지표를 쓰는 것이 바람직함
결과 보고서 작성
지금까지의 분석 결과를 바탕으로 보고서를 작성하는 단계
분석 목적, 데이터 탐색 및 전처리, 분석 방법, 분석 결과 및 활용 방안
부적절한 문제 정의
구체적이지 않은 문제 정의
부적절한 특징 정의
수집 불가한 데이터 정의
부적절한 데이터 수집
측정 오류 등으로 수집한 데이터가 실제 상황을 반영하지 못하는 경우
해결하고자 하는 문제와 무관한 데이터를 수집한 경우
특정 이벤트가 데이터에 누락된 경우
부적절한 데이터 탐색
피드백 루프를 발생시키는 핵심 원인이 부적절한 데이터 탐색 혹은 데이터 탐색 생략임
데이터 탐색을 제대로 하지 않으며, 적절한 모델 선택 및 전처리를 할 수 없어, 모델 평가 단계에서 좋은 성능을 내는 것이 거의 불가능함
부적절한 데이터 전처리
데이터 전처리는 크게 모델 개발을 위해 필수적인 전처리와 모델 성능 향상을 위한 전처리로 구분됨
보통 모델 성능 향상을 위한 전처리를 생략해서 이전 단계로 되돌아가는 경우가 가장 흔함
부적절한 모델링 및 모델 평가
모델링에서 주로 부적절한 모델 및 파라미터 선택으로 잘못되는 경우가 대부분이며, 모델링 자체가 잘못되는 경우는 매우 드물다
모델 평가는 적절하지 않은 지표를 사용해서 잘못되는 경우가 대부분이며, 대표적인 사례로 단일 지표만 써서 부적절한 모델을 우수한 모델이라고 판단하는 경우가 있음

3. 주요 모델의 구조 및 특성
선형 회귀 모델과 정규화 회귀 모델
비용 함수 : 오차 제곱합
특징과 라벨 간 비선형 관계가 무시될 수 있으므로, 특징 변환이 필요
특징 간 스케일 차이에 크게 영향을 받아, 예측 모델링을 할 때 스케일링이 필요함
로지스틱 회귀 모델
비용 함수 : 크로스 엔트로피
특징의 구간 별로 라벨의 분포가 달라지는 경우, 적절한 구간을 나타낼 수 있도록 특징 변환이 필요함
K-최근접 이웃(K-Nearest Neighbors KNN)
분류 / 예측
주요 파라미터와 설정 방법
이웃 수 : 홀수로 설정하여, 특징 수 대비 샘플 수가 적은 경우에는 k를 작게 설정하는 것이 바람직함
거리 및 유사도 척도 : 맨하탄 거리, 코사인 유사도, 매칭 유사도, 자카드 유사도, 유클리디안 거리
특징 추출이 어려우나 유사도 및 거리 계산만 가능한 경우(시퀀스 데이터)에 주로 활용
모든 특징이 연속형이고 샘플 수가 많지 않은 경우에는 좋은 성능을 보인다고 알려져 있음
특징 간 스케일 차이에 크게 영향을 받아, 스케일링이 반드시 필요함 (코사인 유사도는 방향성을 보기에 제외함)
거리 및 유사도 계산에 문제가 없다면 별다른 특징 변환이 필요하지 않음
의사결정나무 (Decision Tree)
나무 구조 / 규칙 집합
예측 과정을 잘 설명할 수 있다는 장점 때문에 많은 프로젝트에서 활용
선형 분류기라는 한계로 예측력이 좋은 편에 속하지는 못하나, 최근 각광받고 있는 아상블 모델 : XGBoost, LightGBM의 기본 모형으로 사용됨
주요 파라미터
max_depth : 최대 깊이
min_samples_leaf : 앞 노드에 있어야 하는 최소 샘플 수
나이브 베이즈 
베이즈 정리를 사용하고 특징 간 독립을 가정하여 사후 확률을 계산
가능도는 조건부 분포를 가정하여 추정함 : 이진형, 범주형, 연속형
모델 특성
특징 간 독립 가정이 실제로는 굉장히 비현실적이므로, 높은 성능을 기대하긴 어려움
설정한 분포에 따라 성능 차이가 크므로, 특징 타입이 서로 같은 경우에 사용하기 바람직
특징이 매우 많고 그 타입이 같은 문제(이진형 텍스트 분류)에 주로 사용됨
서포트 벡터 머신
최적화 모델 : 목적식, 제약식
오차를 최소화 하면서 동시에 마진을 최대화 하는 분류 모델로, 커널 트릭을 활용하여 저차원 공간을 고차원 공간으로 매핑함
마진의 개념을 회귀에 활용한 모델을 서포트 벡터 회귀이라 함
주요 파라미터 : kernel, C, r
파라미터 튜닝이 까다로운 모델이지만, 튜닝만 잘하면 좋은 성능을 보장하는 모델임
신경망 (Neural Network)
입력 노드 : 입력 값을 받는 역할
은닉 노드 및 출력 노드 : 입력 노드 혹은 다른 은닉 노드로부터 들어온 값들을 가중합하고 활성함수를 적용하여 출력을 냄
초기 가중치에 크게 영향을 받음
은닉 노드가 하나 추가되면 그에 따라 하나 이상의 가중치가 추가되어 복잡도가 크게 증가함
모든 변수 타입이 연속형인 경우 성능이 잘 나오는 것으로 알려져 있으며, 은닉 층 구조에 따른 복잡도 조절이 파라미터 튜닝에서 고려해야 할 가장 중요한 요소
최근 딥러닝 발전으로 크게 주목받는 모델이나 특정 주제를 제외하고는 깊은 층의 신경망은 과적합으로 인한 성능 이슈가 자주 발생함
트리 기반의 앙상블 모델
램덤 포레스트 : 배깅 방식 : 트리의 개수와 나무의 최대 깊이 조정 필요
XGboost & LightGBM : 부스팅 방식 : 트리의 개수, 나무의 최대 깊이, 학습률을 조정해야 함

4. 지도학습 모델 & 파라미터 선택 : 그리드 서치
모델 및 파라미터 선정 문제
어떠한 데이터에 대해서도 우수한 모델과 그 하이퍼 파라미터는 절대 존재하지 않음
분석적 방법으로 좋은 모델과 하이퍼 파라미터를 선정하는 것도 불가능함
그리드 서치 개요
하이퍼 파라미터 그리드는 한 모델의 하이퍼 파라미터 조합이며, 그리드 서치란 하이퍼 파라미터 그리드에 속한 모든 파라미터 조합을 비교 평가하는 방법을 의미함
그리드 서치 코드 구현
sklearn을 활용하여 그리드 서치를 구현하려면 사전 형태로 하이퍼 파라미터 그리드를 정의해야 함 : key, value
GridSearchCV : 사용이 편하다는 장점이 있지만, k-겹 교차 검증 방식을 사용하기에 느리고, 성능 향상을 위한 전처리 적용할 수 없다는 단점이 있음
ParameterGrid : GridSearchCV에 비해 사용이 어렵다는 단점이 있지만, 성능 향상을 위한 전처리 기법을 적용하는데 문제가 없어서 실무에서 훨씬 자주 사용함
사전 앞에 **를 붙여야 함
최소 값/ 최대값을 찾는 알고리즘

5. 지도학습 모델 & 파라미터 선택 : 기준 변수 타입
변수 타입 확인 방법
DataFrame.dtypes
Data Frame.objects().dtypes
string type이라고 해서 반드시 범주형이 아니며, int 혹은 float type이라고 해서 반드시 연속형은 아님. 반드시 상태 공간의 크기와 도메인 지식 등을 고려해야 함
변수 타입
변수 타입에 따른 적절한 모델
혼합형 변수에 적절하지 않은 모델
회귀 모델
혼합형 변수인 경우에는 변수의 스케일 차이가 존재하는 경우가 흔함
변수의 스케일에 따라 계수 값이 크게 달라지므로, 예측 안정성이 크게 떨어짐
스케일링을 하더라도 이진형 특징의 분포가 변하지 않으므로, 이진형 특징의 값에 따른 영향력이 크게 줄지 않음
나이브 베이즈
하나의 확률 분포를 가정하기에 혼합형 변수를 가지는 데이터에 부적절함
혼합형 변수에는 절대 고려하면 안되는 모델
K-최근접 이웃
스케일이 큰 변수에 의해 거리가 사실상 결정되므로, K-NN은 혼합형 변수에 적절하지 않음
단, 코사인 유사도를 사용하는 경우나, 스케일링을 적용하는 경우에는 무리 없이 사용 가능함

6. 지도학습 모델 & 파라미터 선택 : 기준 데이터 크기
샘플 개수와 특징 개수에 따른 과적합
샘플 개수와 특징 개수에 따른 적절한 모델
매우 단순
매우 복잡
적당히 단순
적당히 복잡

7. 지도학습 모델 & 파라미터 선택 : 복잡도 파라미터 튜닝 방법
복잡도 파라미터
복잡도에 영향을 주는 파라미터로, 이 값에 따라 과적합 정도가 결정되므로 매우 신중하게 튜닝해야 함

모델
파라미터
영향
휴리스틱하게 학습되는 모든 모델
max_iter
복잡한 모델의 경우 이 값이 클수록 학습 시간이 오래 소요되고 과적합으로 이어질 수 있음

따라서 복잡한 모델을 학습 할 때 일부러 max_iter를 작게 잡아서 과적합을 회피하기도 함
정규화 회귀모델
alpha
복잡도와 정비례 관계
의사결정나무
max_depth
복잡도와 정비례 관계
min_samples_leaf
복잡도와 반비례 관계
SVM
C.gamma, degree
복잡도와 약한 정비례 관계 (영향을 줄 수도 아닐 수도 있음)
kernel
poly > rbf > linear 순으로 과적합 가능성이 높음
로지스틱 회귀
C
복잡도와 반비례 관계
신경망
hidden_layer_sizes
복잡도와 강한 정비례 관계

hidden_layer_sizes에 따라 가중치 개수가 결정되고 가중치 개수가 복잡도를 결정함
SVR
epsilon
복잡도와 강한 반비례 관계
Tree Ensemble
max_depth
복잡도와 정비례 관계, 과적합을 피하기 위해 보통 4이하로 설정
learning rate
(랜덤 포레스트 제외)
복잡도와 정비례 관계


학습 시 우연성이 개입되는 모델의 복잡도 파라미터 튜닝
경사하강법 등의 방법으로 학습되는 모델은 초기값에 의한 영향이 매우 큼
따라서 복잡도 파라미터 변화에 따른 성능 변화의 패턴을 확인하기 어려운 경우가 많아서, seed를 고정한 뒤 튜닝을 수행해야 함

복잡도 파라미터 튜닝
seed가 고정되어 있거나 학습 시 우연 요소가 개입되지 않는 모델의 경우 복잡도 파라미터에 따른 성능 변화 패턴 확인이 상대적으로 쉬움
복잡도 파라미터가 둘 이상인 경우에 서로 영향을 주기 때문에 반드시 두 파라미터를 같이 조정해야 함
파라미터 그리드 크기를 줄이기 위해 몇 가지 파라미터 값을 테스트 한 후 범위를 설정하는 것이 바람직함







